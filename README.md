# Home Credit Default Risk â€“ Fair AI in Finance

This project explores the [Kaggle Home Credit Default Risk competition](https://www.kaggle.com/competitions/home-credit-default-risk) as a case study in **AI for Finance**, focusing on predictive performance **and** fairness/explainability for regulatory alignment.

## ðŸ“‚ Project Structure
- `homecredit.ipynb` â€“ Main analysis (data prep, modeling, explainability, fairness)
- `baseline_model_comparison.csv` â€“ Baseline model metrics
- `shaplike_global_importance.csv` â€“ Global SHAP feature importance
- `local_explain_highrisk.csv` â€“ Local SHAP for high-risk cases
- `local_explain_lowrisk.csv` â€“ Local SHAP for low-risk cases
- `local_explain_borderline.csv` â€“ Local SHAP for borderline cases
- `fairness_by_gender.csv` â€“ Fairness metrics by gender
- `fairness_by_age_group.csv` â€“ Fairness metrics by age group
- `week3_mitigation_comparison.csv` â€“ Fairness mitigation experiments
- `Model Performance and Fairness Analysis for Home Credit.docx` â€“ Original draft report
- `Home_Credit_Final_Report_v2.docx` â€“ Final polished report (this repo)

## ðŸš€ Workflow
1. **Data Preparation** â€“ Merge application/bureau/previous loans; impute missing values; engineer credit utilization, repayment history, ratios.
2. **Modeling** â€“ Logistic Regression (baseline, interpretable) vs. LightGBM (non-linear). Train/val/test with cross-validation.
3. **Evaluation** â€“ AUC, accuracy, precision, recall.
4. **Explainability** â€“ Global SHAP for feature ranking; local SHAP for case-level reasoning.
5. **Fairness** â€“ Selection rate, TPR (equal opportunity), FPR across gender and age groups.
6. **Mitigations** â€“ Threshold tuning and re-weighting experiments (`week3_mitigation_comparison.csv`).

## ðŸ“Š Key Results
- **Best overall**: LightGBM (AUC 0.778; Accuracy 0.757). Logistic Regression close (AUC 0.767; Accuracy 0.707).
- **Precision challenge**: < 0.20 for both models â†’ many false alarms among predicted defaults.
- **Top predictors**: External credit scores (EXT_SOURCE_1â€“3); loan size variables.
- **Fairness**:
  - Males and younger applicants flagged more frequently â†’ higher detection but more false positives.
  - Older applicants flagged less often â†’ more missed defaults.

## ðŸ›ï¸ Policy Recommendations (Summary)
- Mandate **fairness audits** with clear metrics.
- Standardize **explainability** (e.g., SHAP) for regulators and consumers.
- Use **fairness-aware modeling** (re-weighting, thresholds, post-processing).
- Strengthen **data governance** and transparency in **decision thresholds**.
- Align with **EU AI Act** principles for high-risk AI systems.

## ðŸ§ª Reproducibility
- Open `homecredit.ipynb` in Jupyter/Colab.
- Ensure Kaggle data is available under the working directory according to competition terms.
- Run cells sequentially; outputs (CSVs and the final report) will be produced in the working directory.

## ðŸŽ¯ Purpose
This repository is part of a **PhD portfolio project** (AI in Finance), demonstrating end-to-end modeling with fairness and explainability for regulator-ready reporting.
